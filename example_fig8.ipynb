{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST API for PACO server\n",
    "\n",
    "\n",
    "The docs is available at http://localhost:8080/docs or at [docs](http://localhost:8080/docs) "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#################\n",
    "# IMPORTS\n",
    "#################\n",
    "import requests\n",
    "import getpass\n",
    "import random\n",
    "import string\n",
    "from paco.parser.parse_tree import ParseTree\n",
    "from paco.execution_tree.execution_tree import ExecutionTree\n",
    "from paco.explainer.bdd.bdds import bdds_from_json\n",
    "\n",
    "#################\n",
    "# HEADERS\n",
    "#################\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "url = \"http://127.0.0.1:8000/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the *BPMN+CPI*\n",
    "\n",
    "In the following cell the *BPMN+CPI* is defined. \n",
    " - expression: A string representing the BPMN expression, which defines the sequence and parallelism of tasks.\n",
    " - impacts: A dictionary where keys are task names and values are lists of impacts (e.g., costs, durations).\n",
    " - durations: A dictionary where keys are task names and values are lists representing the duration range [min, max] for each task.\n",
    " - probabilities: A dictionary where keys are natures (e.g., 'N1') and values are their probabilities.\n",
    " - loop_round: A dictionary for defining loop rounds, if any.\n",
    " - names: A dictionary mapping event names to their string representations that are displayed when the bpmn is drawn.\n",
    " - delays: A dictionary where keys are event names (e.g., 'C1') and values are their delays.\n",
    " - loop_probability: A dictionary for defining loop probabilities, if any.\n",
    " - impacts_names: A list of impact names (e.g., ['cost_electricity']).\n",
    "\n",
    "### Example in Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bpmn = {\n",
    "    \"expression\": \"(Cutting, ((Bending, (HP^[N1]LP)) || (Milling, (FD/[C1]RD))), (HPHS / [C2] LPLS))\",\n",
    "    \"impacts\": {\"Cutting\": [10, 1], \"Bending\": [20, 1],\n",
    "        \"Milling\": [50, 1], \"HP\": [5, 4], \"LP\": [8, 1],\n",
    "        \"FD\": [30, 1], \"RD\": [10, 1], \"HPHS\": [40, 1],\n",
    "        \"LPLS\": [20, 3]\n",
    "    },\n",
    "    \"durations\": {\"Cutting\": [0, 1], \"Bending\": [0, 1],\n",
    "        \"Milling\": [0, 1], \"HP\": [0, 2], \"LP\": [0, 1],\n",
    "        \"FD\": [0, 1], \"RD\": [0, 1], \"HPHS\": [0, 1],\n",
    "        \"LPLS\": [0, 2]},\n",
    "    \"impacts_names\": [\"electric_energy\", \"worker hours\"], \n",
    "    \"probabilities\": {\"N1\": 0.2}, \n",
    "    \"delays\": {\"C1\": 0, \"C2\": 0},\n",
    "    \"names\": {\"C1\": \"C1\", \"C2\": \"C2\", \"N1\": \"N1\"}, \n",
    "    \"loops_prob\" : {}, \"loops_round\": {}, \"h\": 0,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the expression compliy with the defined grammmar"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "resp = requests.get(f'{url}check_correct_process_expression', params={'expression': bpmn['expression']},  headers=headers)\n",
    "if resp.status_code != 200:\n",
    "    print('Error in the request', resp.text)\n",
    "elif resp.text == 'true':\n",
    "    print('BPMN grammar is correct')\n",
    "else:\n",
    "    print('BPMN grammar is incorrect')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Diagram"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import graphviz\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "data = {\n",
    "    \"bpmn\": bpmn, \n",
    "}\n",
    "response = requests.post(f'{url}create_sese_diagram', json=data,  headers=headers)\n",
    "# Check if response is successful and save the file as a svg\n",
    "if response.status_code == 200:\n",
    "    display(SVG(graphviz.Source(response.json()['graph']).pipe(format=\"svg\")))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create the parse tree and execution tree"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = requests.get(f'{url}create_execution_tree', json={\"bpmn\": bpmn},  headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response = response.json()\n",
    "    parse_tree, _,_ = ParseTree.from_json(response[\"parse_tree\"], len(bpmn[\"impacts_names\"]), 0)\n",
    "\n",
    "    bound = parse_tree.sample_expected_impact()\n",
    "    print(f\"Sampled Expected Impact: {bound}\")\n",
    "\n",
    "    display(SVG(graphviz.Source(parse_tree.to_dot()).pipe(format=\"svg\")))\n",
    "\n",
    "    execution_tree = ExecutionTree.from_json(parse_tree, response[\"execution_tree\"], bpmn[\"impacts_names\"])\n",
    "    dot = execution_tree.to_dot(state=True, executed_time=True, diff=True)\n",
    "    display(SVG(graphviz.Source(dot).pipe(format=\"svg\")))\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolate Explained Strategy\n",
    "\n",
    "\n",
    "Remember to choose an appropriate bound.\n",
    "\n",
    "All the times are in ms"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = requests.get(\n",
    "    f'{url}calc_strategy_general',\n",
    "    json={\n",
    "        'bpmn': bpmn,\n",
    "        'bound': bound,\n",
    "        'algo': 'paco',\n",
    "    },\n",
    "    headers=headers,\n",
    ")\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "else:\n",
    "    response = response.json()\n",
    "    print(response[\"result\"])\n",
    "    parse_tree, pending_choice, pending_natures = ParseTree.from_json(response[\"parse_tree\"], len(bpmn[\"impacts_names\"]), 0)\n",
    "    dot = parse_tree.to_dot()\n",
    "    display(SVG(graphviz.Source(dot).pipe(format=\"svg\")))\n",
    "\n",
    "    execution_tree = ExecutionTree.from_json(parse_tree, response[\"execution_tree\"], bpmn[\"impacts_names\"])\n",
    "\n",
    "    frontier_solution_id = set()\n",
    "    if \"frontier_solution\" in response: # Solution Found\n",
    "        frontier_solution_id = set(map(int, response[\"frontier_solution\"].strip(\"[]\").split(\",\")))\n",
    "\n",
    "    # With frontier node in blue\n",
    "    dot = execution_tree.to_dot(state=True, executed_time=False, diff=True, frontier=frontier_solution_id)\n",
    "    display(SVG(graphviz.Source(dot).pipe(format=\"svg\")))\n",
    "\n",
    "\n",
    "    if \"strategy_tree\" in response:\n",
    "        explained_choices = bdds_from_json(parse_tree, response[\"bdds\"])\n",
    "        print(\"1 is dashed line of BPMN or Parse Tree\")\n",
    "        for choice, bdd in explained_choices.items():\n",
    "            print(f\"{choice.name} : {bdd.typeStrategy}\")\n",
    "            svg_data = graphviz.Source(bdd.bdd_to_dot()).pipe(format=\"svg\")\n",
    "            display(SVG(svg_data))\n",
    "\n",
    "\n",
    "        strategy_tree = ExecutionTree.from_json(parse_tree, response[\"strategy_tree\"], bpmn[\"impacts_names\"], explained_choices)\n",
    "\n",
    "        #TREE_STATE\n",
    "        dot = strategy_tree.to_dot(state=True, executed_time=False, diff=True)\n",
    "        display(SVG(graphviz.Source(dot).pipe(format=\"svg\")))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM\n",
    "\n",
    "### Chat with the LMM "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "session_id = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(8))\n",
    "##################################\n",
    "# SET THE DATA FOR THE LLM\n",
    "##################################\n",
    "data = {\n",
    "    \"session_id\": session_id,\n",
    "    \"url\": input(\"Enter the URL of the model: \"),\n",
    "    \"api_key\": getpass.getpass(\"Enter the API key: \"),\n",
    "    \"model\": input(\"Enter the the model: \"),\n",
    "    \"temperature\": 0.7,\n",
    "    \"verbose\": False,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# If wanted can be used also this predefined prompt that consituates the example found in the paper\n",
    "# prompt = '''\n",
    "# Now I have to complete the writing task before \n",
    "# having a nature between talking with the publisher or to print the page written.\n",
    "# Then, I choose between going to the coffee or go to the gym.\n",
    "# '''\n",
    "prompt = input(\"Enter your prompt: \")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data[\"prompt\"] = prompt\n",
    "response = requests.post(f'{url}invoke_agent', headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.json()['response'])\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Chat History"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = requests.get(f'{url}get_chat_history', headers=headers, params={\"session_id\": session_id})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    for message in response.json():\n",
    "        if message[\"role\"] == \"human\":\n",
    "            print(f\"User: {message['content']}\")\n",
    "        elif message[\"role\"] == \"ai\":\n",
    "            print(f\"Assistant: {message['content']}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
