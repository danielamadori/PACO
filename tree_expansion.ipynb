{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Execution Tree Expansion\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a **complete execution tree expansion algorithm** that explores all possible execution paths in a BPMN process by enumerating all combinations of simultaneous Choice and Nature nodes.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "When a BPMN process contains parallel execution branches with multiple decision points (Choice nodes) or probabilistic branches (Nature nodes), the execution tree must capture **all possible combinations** of choices across these simultaneous decision points.\n",
    "\n",
    "### Key Challenges:\n",
    "\n",
    "1. **Simultaneous Decisions**: Multiple Choice/Nature nodes can be enabled at the same time (parallel execution)\n",
    "2. **Combinatorial Explosion**: With N decision points having M alternatives each, we need to explore M^N combinations\n",
    "3. **Node Identification**: The simulator may assign the same ID to different execution paths, requiring differentiation by impacts and probability\n",
    "4. **Server Interface**: The server uses transitions with `stop=True` to represent decision points and expects a list of transition IDs as choices\n",
    "\n",
    "## Algorithm Design\n",
    "\n",
    "### Core Strategy:\n",
    "\n",
    "```\n",
    "For each node to expand:\n",
    "  1. Identify all enabled stop transitions (decision points)\n",
    "  2. Group transitions by label (representing Choice/Nature nodes)\n",
    "  3. Generate cartesian product of all alternatives\n",
    "  4. For each combination:\n",
    "     - Call simulator with specific choices\n",
    "     - Collect resulting child nodes\n",
    "  5. Deduplicate children by (impacts, probability) signature\n",
    "  6. Update tree with all unique children\n",
    "  7. Continue BFS traversal\n",
    "```\n",
    "\n",
    "### Example:\n",
    "\n",
    "If we have:\n",
    "- **C1** (Choice): 2 alternatives [FD, RD]\n",
    "- **N1** (Nature): 2 alternatives [HP, LP] with probabilities [0.2, 0.8]\n",
    "\n",
    "Both enabled simultaneously \u2192 **4 combinations** to explore:\n",
    "1. (FD, HP) \u2192 impacts=[X1, Y1], prob=0.2\n",
    "2. (FD, LP) \u2192 impacts=[X2, Y2], prob=0.8\n",
    "3. (RD, HP) \u2192 impacts=[X3, Y3], prob=0.2\n",
    "4. (RD, LP) \u2192 impacts=[X4, Y4], prob=0.8\n",
    "\n",
    "Each combination produces a unique child node in the execution tree."
   ],
   "id": "intro"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ],
   "id": "setup_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('simulator/src')\n",
    "sys.path.append('src')\n",
    "import copy\n",
    "from itertools import product\n",
    "from collections import deque\n",
    "from typing import Any, Dict, List, Optional\n",
    "import requests\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "from IPython.core.display import SVG\n",
    "from src.utils.env import IMPACTS_NAMES\n",
    "\n",
    "# Configuration\n",
    "URL = \"127.0.0.1\"\n",
    "SIMULATOR_PORT = 8001\n",
    "SOLVER_PORT = 8000\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}"
   ],
   "id": "imports",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BPMN Definition\n",
    "\n",
    "Load the BPMN process definition from JSON file. This contains:\n",
    "- Process structure (activities, gateways, flows)\n",
    "- Impact definitions (resources consumed)\n",
    "- Duration and cost information"
   ],
   "id": "load_bpmn_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open(\"bpmn_fig8_bound_135_15.json\", \"r\") as f:\n",
    "    bpmn_file = f.read()\n",
    "\n",
    "bpmn_definition = json.loads(bpmn_file)\n",
    "impacts_names = bpmn_definition.get(IMPACTS_NAMES, [])\n",
    "print(f\"Loaded BPMN: {bpmn_definition.get('expression', '')}\")\n",
    "print(f\"Impact dimensions: {impacts_names}\")"
   ],
   "id": "load_bpmn",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Parse Tree and Visualize BPMN\n",
    "\n",
    "The solver API converts the BPMN definition into:\n",
    "1. **BPMN visualization** - Graphical representation of the process\n",
    "2. **Parse tree** - Hierarchical structure for execution"
   ],
   "id": "parse_tree_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    # Create BPMN visualization\n",
    "    resp = requests.get(f\"http://{URL}:{SOLVER_PORT}/create_bpmn\", json={'bpmn': bpmn_definition}, headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    bpmn_payload = resp.json()\n",
    "    bpmn_dot = bpmn_payload.get('bpmn_dot')\n",
    "    if bpmn_dot:\n",
    "        try:\n",
    "            svg_bytes = graphviz.Source(bpmn_dot).pipe(format=\"svg\")\n",
    "            display(SVG(svg_bytes))\n",
    "        except graphviz.backend.execute.ExecutableNotFound as exc:\n",
    "            print(f\"\u26a0\ufe0f Unable to render BPMN SVG locally: {exc}\")\n",
    "\n",
    "    # Create parse tree\n",
    "    resp = requests.get(f\"http://{URL}:{SOLVER_PORT}/create_parse_tree\", json={'bpmn': bpmn_definition}, headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    parse_tree = resp.json().get('parse_tree', {})\n",
    "    print(\"\u2713 Parse tree created successfully\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\u2717 Error while contacting solver: {e}\")\n",
    "    parse_tree = {}\n",
    "\n"
   ],
   "id": "parse_tree",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "### Core Utilities:\n",
    "\n",
    "- **`get_node_by_id`**: Recursive tree traversal to find a node by ID\n",
    "- **`is_final_node`**: Check if a node represents the final marking (end state)\n",
    "- **`count_nodes`**: Count total nodes in the tree (for statistics)\n",
    "- **`get_stop_transitions`**: Identify enabled decision points from the Petri net\n",
    "- **`node_signature`**: Create unique fingerprint for nodes based on impacts and probability"
   ],
   "id": "utils_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_node_by_id(root: Dict[str, Any], node_id: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Find a node by its ID in the execution tree.\n",
    "\n",
    "    Args:\n",
    "        root: Root node of the tree\n",
    "        node_id: ID of the node to find\n",
    "\n",
    "    Returns:\n",
    "        Node dictionary if found, None otherwise\n",
    "    \"\"\"\n",
    "    if root.get(\"id\") == node_id:\n",
    "        return root\n",
    "    for child in root.get(\"children\", []):\n",
    "        result = get_node_by_id(child, node_id)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_final_node(node: Dict[str, Any], final_marking: Dict[str, Dict[str, float]]) -> bool:\n",
    "    \"\"\"Check if a node represents a final marking (end state).\n",
    "\n",
    "    Args:\n",
    "        node: Node to check\n",
    "        final_marking: Expected final marking from Petri net\n",
    "\n",
    "    Returns:\n",
    "        True if node is in final state\n",
    "    \"\"\"\n",
    "    marking = node.get(\"snapshot\", {}).get(\"marking\", {})\n",
    "    if not marking or not final_marking:\n",
    "        return False\n",
    "    for place_name, place_data in final_marking.items():\n",
    "        if marking.get(place_name, {}).get(\"token\", 0) != place_data.get(\"token\", 0):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def count_nodes(node: Dict[str, Any]) -> int:\n",
    "    \"\"\"Recursively count all nodes in the tree.\n",
    "\n",
    "    Args:\n",
    "        node: Root node\n",
    "\n",
    "    Returns:\n",
    "        Total number of nodes including subtrees\n",
    "    \"\"\"\n",
    "    total = 1\n",
    "    for child in node.get(\"children\", []):\n",
    "        total += count_nodes(child)\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_stop_transitions(petri_net: Dict[str, Any], marking: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Get all enabled stop transitions, grouped by label.\n",
    "\n",
    "    Stop transitions represent decision points (Choice/Nature nodes) in the process.\n",
    "    This function:\n",
    "    1. Filters transitions with stop=True\n",
    "    2. Checks which are enabled in the current marking\n",
    "    3. Groups them by label (representing the same decision point)\n",
    "\n",
    "    Args:\n",
    "        petri_net: Petri net structure\n",
    "        marking: Current marking (token distribution)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping label -> [transition_ids]\n",
    "        Example: {'C1': ['t5', 't6'], 'N1': ['t7', 't8']}\n",
    "    \"\"\"\n",
    "    transitions = petri_net.get(\"transitions\", [])\n",
    "    enabled_stop = {}\n",
    "\n",
    "    for trans in transitions:\n",
    "        if not trans.get('stop', False):\n",
    "            continue\n",
    "\n",
    "        trans_id = trans.get('id')\n",
    "        trans_label = trans.get('label')\n",
    "        inputs = trans.get('inputs', [])\n",
    "\n",
    "        # Check if transition is enabled (all input places have tokens)\n",
    "        enabled = True\n",
    "        for place_id in inputs:\n",
    "            if place_id not in marking or marking[place_id].get('token', 0) <= 0:\n",
    "                enabled = False\n",
    "                break\n",
    "\n",
    "        if enabled:\n",
    "            if trans_label not in enabled_stop:\n",
    "                enabled_stop[trans_label] = []\n",
    "            enabled_stop[trans_label].append(trans_id)\n",
    "\n",
    "    return enabled_stop\n",
    "\n",
    "\n",
    "def _collect_transition_ids(entry: Any) -> List[str]:\n",
    "    \"\"\"Collect transition identifiers from a generic status entry.\"\"\"\n",
    "    identifiers: List[str] = []\n",
    "\n",
    "    if isinstance(entry, str):\n",
    "        identifiers.append(entry)\n",
    "    elif isinstance(entry, list):\n",
    "        for item in entry:\n",
    "            identifiers.extend(_collect_transition_ids(item))\n",
    "    elif isinstance(entry, dict):\n",
    "        for key, value in entry.items():\n",
    "            if key == \"label\":\n",
    "                continue\n",
    "            if isinstance(value, str):\n",
    "                if key in {\"id\", \"transition\", \"transition_id\", \"name\"}:\n",
    "                    identifiers.append(value)\n",
    "            else:\n",
    "                identifiers.extend(_collect_transition_ids(value))\n",
    "\n",
    "    # Remove duplicates while preserving order\n",
    "    seen: set[str] = set()\n",
    "    ordered_ids: List[str] = []\n",
    "    for identifier in identifiers:\n",
    "        if identifier not in seen:\n",
    "            seen.add(identifier)\n",
    "            ordered_ids.append(identifier)\n",
    "    return ordered_ids\n",
    "\n",
    "\n",
    "def _collect_active_labels(active_markings: Any) -> List[str]:\n",
    "    \"\"\"Normalize active marking metadata into a list of labels.\"\"\"\n",
    "    labels: List[str] = []\n",
    "\n",
    "    def _visit(entry: Any) -> None:\n",
    "        if isinstance(entry, str):\n",
    "            labels.append(entry)\n",
    "        elif isinstance(entry, dict):\n",
    "            candidate = entry.get(\"label\") or entry.get(\"id\") or entry.get(\"name\")\n",
    "            if isinstance(candidate, str):\n",
    "                labels.append(candidate)\n",
    "            for key, value in entry.items():\n",
    "                if key not in {\"label\", \"id\", \"name\"}:\n",
    "                    _visit(value)\n",
    "        elif isinstance(entry, list):\n",
    "            for item in entry:\n",
    "                _visit(item)\n",
    "\n",
    "    _visit(active_markings)\n",
    "\n",
    "    if isinstance(active_markings, dict):\n",
    "        ignored_keys = {\"type\", \"state\", \"message\", \"current_node\", \"history\"}\n",
    "        for key in active_markings:\n",
    "            if isinstance(key, str) and key not in ignored_keys:\n",
    "                labels.append(key)\n",
    "\n",
    "    seen: set[str] = set()\n",
    "    ordered: List[str] = []\n",
    "    for label in labels:\n",
    "        if label not in seen:\n",
    "            seen.add(label)\n",
    "            ordered.append(label)\n",
    "    return ordered\n",
    "\n",
    "\n",
    "def get_stop_groups_from_status(\n",
    "    status: Dict[str, Any],\n",
    "    *,\n",
    "    active_markings: Optional[Any] = None,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"Extract decision points from the snapshot status structure.\n",
    "\n",
    "    The simulator enriches each snapshot with a ``status`` field describing the\n",
    "    decisions that are currently available.  This helper normalizes the different\n",
    "    shapes returned by the simulator so that the expansion algorithm can operate\n",
    "    purely based on the status information provided by the snapshot, without\n",
    "    re-deriving enabled transitions from the Petri net.  When available, the\n",
    "    provided ``active_markings`` metadata is used to confirm which decision labels\n",
    "    are currently enabled.\n",
    "    \"\"\"\n",
    "    if not isinstance(status, dict):\n",
    "        return {}\n",
    "\n",
    "    raw_groups: Dict[str, List[str]] = {}\n",
    "\n",
    "    # Some implementations expose the interesting content under well-known keys.\n",
    "    candidate_keys = [\n",
    "        \"decisions\",\n",
    "        \"pending_decisions\",\n",
    "        \"pending\",\n",
    "        \"enabled\",\n",
    "        \"stop_transitions\",\n",
    "    ]\n",
    "\n",
    "    containers: List[Any] = [status.get(key) for key in candidate_keys if key in status]\n",
    "\n",
    "    # The status itself might already expose the mapping label -> entries.\n",
    "    ignored_top_level = {\"type\", \"state\", \"message\", \"current_node\", \"history\"}\n",
    "    for label, entry in status.items():\n",
    "        if label in ignored_top_level or label in candidate_keys:\n",
    "            continue\n",
    "        identifiers = _collect_transition_ids(entry)\n",
    "        if identifiers:\n",
    "            raw_groups[label] = identifiers\n",
    "\n",
    "    for container in containers:\n",
    "        if isinstance(container, dict):\n",
    "            for label, entry in container.items():\n",
    "                identifiers = _collect_transition_ids(entry)\n",
    "                if identifiers:\n",
    "                    raw_groups[label] = identifiers\n",
    "        elif isinstance(container, list):\n",
    "            for item in container:\n",
    "                if not isinstance(item, dict):\n",
    "                    continue\n",
    "                label = item.get(\"label\") or item.get(\"id\") or item.get(\"name\")\n",
    "                if not label:\n",
    "                    continue\n",
    "                identifiers = _collect_transition_ids(item)\n",
    "                if identifiers:\n",
    "                    raw_groups[label] = identifiers\n",
    "\n",
    "    if active_markings:\n",
    "        active_labels = set(_collect_active_labels(active_markings))\n",
    "        if active_labels:\n",
    "            return {label: ids for label, ids in raw_groups.items() if label in active_labels}\n",
    "\n",
    "    return raw_groups\n",
    "\n",
    "\n",
    "def node_signature(node: Dict[str, Any]) -> tuple:\n",
    "    \"\"\"Create a unique signature for a node based on impacts and probability.\n",
    "\n",
    "    Since the server may assign the same ID to different execution paths,\n",
    "    we need to differentiate nodes by their actual state (impacts) and\n",
    "    probability (for Nature nodes).\n",
    "\n",
    "    Args:\n",
    "        node: Node to fingerprint\n",
    "\n",
    "    Returns:\n",
    "        Tuple (impacts, probability) for use as dictionary key\n",
    "    \"\"\"\n",
    "    impacts = tuple(node['snapshot']['impacts'])\n",
    "    prob = node['snapshot']['probability']\n",
    "    return (impacts, prob)\n",
    "\n",
    "\n",
    "print(\"\u2713 Utility functions loaded\")\n"
   ],
   "id": "utils",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimulatorClient Class\n",
    "\n",
    "Client wrapper for the simulator API.\n",
    "\n",
    "### Key Methods:\n",
    "\n",
    "- **`bootstrap`**: Initialize simulation with parse tree\n",
    "- **`expand_node`**: Expand a specific node with given choices\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "- The server operates on `execution_tree.current_node`\n",
    "- Choices are passed as a list of transition IDs\n",
    "- Each call returns updated state (petri_net, execution_tree, etc.)"
   ],
   "id": "client_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class HttpSimulatorClient:\n",
    "    \"\"\"HTTP client for interacting with the simulator API.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str) -> None:\n",
    "        self.base_url = base_url.rstrip(\"/\") + \"/\"\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def check_connection(self) -> None:\n",
    "        \"\"\"Validate that the remote simulator is reachable.\"\"\"\n",
    "        response = self.session.get(self.base_url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        response = self.session.post(\n",
    "            self.base_url + \"execute\",\n",
    "            headers=HEADERS,\n",
    "            json=payload,\n",
    "            timeout=60,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if \"error\" in data:\n",
    "            raise RuntimeError(f\"Simulator error: {data['error']}\")\n",
    "        return data\n",
    "\n",
    "    def bootstrap(self, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        payload = {\"bpmn\": parse_tree_payload}\n",
    "        return self.execute(payload)\n",
    "\n",
    "    def expand_node(\n",
    "        self,\n",
    "        shared_state: Dict[str, Any],\n",
    "        node_id: str,\n",
    "        *,\n",
    "        choices: Optional[List[str]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        exec_tree = copy.deepcopy(shared_state[\"execution_tree\"])\n",
    "        exec_tree[\"current_node\"] = node_id\n",
    "\n",
    "        request_payload = {\n",
    "            \"bpmn\": shared_state[\"bpmn\"],\n",
    "            \"petri_net\": shared_state[\"petri_net\"],\n",
    "            \"execution_tree\": exec_tree,\n",
    "        }\n",
    "        if choices is not None:\n",
    "            request_payload[\"choices\"] = list(choices)\n",
    "\n",
    "        return self.execute(request_payload)\n",
    "\n",
    "\n",
    "class SnapshotSimulatorClient:\n",
    "    \"\"\"Offline simulator that replays a pre-recorded snapshot.\"\"\"\n",
    "\n",
    "    def __init__(self, snapshot_path: str) -> None:\n",
    "        with open(snapshot_path, \"r\", encoding=\"utf-8\") as handle:\n",
    "            payload = json.load(handle)\n",
    "        self.initial_state: Dict[str, Any] = payload.get(\"initial_state\", {})\n",
    "        self.expansions: Dict[str, Dict[str, List[Dict[str, Any]]]] = payload.get(\"expansions\", {})\n",
    "\n",
    "    def _find_node(self, node: Optional[Dict[str, Any]], node_id: str) -> Optional[Dict[str, Any]]:\n",
    "        if not node:\n",
    "            return None\n",
    "        if node.get(\"id\") == node_id:\n",
    "            return node\n",
    "        for child in node.get(\"children\", []) or []:\n",
    "            found = self._find_node(child, node_id)\n",
    "            if found:\n",
    "                return found\n",
    "        return None\n",
    "\n",
    "    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state = copy.deepcopy(self.initial_state)\n",
    "        if \"bpmn\" in payload:\n",
    "            state[\"bpmn\"] = payload[\"bpmn\"]\n",
    "        if \"execution_tree\" not in payload or \"choices\" not in payload:\n",
    "            return state\n",
    "\n",
    "        node_id = payload.get(\"execution_tree\", {}).get(\"current_node\")\n",
    "        choices = payload.get(\"choices\", [])\n",
    "        key = \"|\".join(choices)\n",
    "\n",
    "        state[\"execution_tree\"] = copy.deepcopy(payload.get(\"execution_tree\", {}))\n",
    "        expansions = self.expansions.get(node_id, {}).get(key, [])\n",
    "        target = self._find_node(state[\"execution_tree\"].get(\"root\"), node_id)\n",
    "        if target is not None:\n",
    "            target[\"children\"] = copy.deepcopy(expansions)\n",
    "        return state\n",
    "\n",
    "    def bootstrap(self, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state = copy.deepcopy(self.initial_state)\n",
    "        state[\"bpmn\"] = parse_tree_payload\n",
    "        return state\n",
    "\n",
    "    def expand_node(\n",
    "        self,\n",
    "        shared_state: Dict[str, Any],\n",
    "        node_id: str,\n",
    "        *,\n",
    "        choices: Optional[List[str]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        exec_tree = copy.deepcopy(shared_state[\"execution_tree\"])\n",
    "        exec_tree[\"current_node\"] = node_id\n",
    "        payload = {\n",
    "            \"bpmn\": shared_state.get(\"bpmn\"),\n",
    "            \"petri_net\": shared_state.get(\"petri_net\"),\n",
    "            \"execution_tree\": exec_tree,\n",
    "        }\n",
    "        if choices is not None:\n",
    "            payload[\"choices\"] = list(choices)\n",
    "        return self.execute(payload)\n",
    "\n",
    "\n",
    "class SimulatorClient:\n",
    "    \"\"\"Facade that prefers the HTTP backend and falls back to the snapshot.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: str = f\"http://{URL}:{SIMULATOR_PORT}/\",\n",
    "        *,\n",
    "        snapshot_path: str = \"snapshots/tree_expansion_snapshot.json\",\n",
    "        force_snapshot: bool = False,\n",
    "    ) -> None:\n",
    "        self.mode = \"snapshot\"\n",
    "        self.client: Any\n",
    "        if not force_snapshot:\n",
    "            try:\n",
    "                http_client = HttpSimulatorClient(base_url)\n",
    "                http_client.check_connection()\n",
    "                self.client = http_client\n",
    "                self.mode = \"http\"\n",
    "            except Exception as exc:\n",
    "                print(f\"\u26a0\ufe0f HTTP simulator unavailable ({exc}); falling back to local snapshot\")\n",
    "                self.client = SnapshotSimulatorClient(snapshot_path)\n",
    "        else:\n",
    "            self.client = SnapshotSimulatorClient(snapshot_path)\n",
    "\n",
    "    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return self.client.execute(payload)\n",
    "\n",
    "    def bootstrap(self, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return self.client.bootstrap(parse_tree_payload)\n",
    "\n",
    "    def expand_node(\n",
    "        self,\n",
    "        shared_state: Dict[str, Any],\n",
    "        node_id: str,\n",
    "        *,\n",
    "        choices: Optional[List[str]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        return self.client.expand_node(shared_state, node_id, choices=choices)\n",
    "\n",
    "\n",
    "print(\"\u2713 Simulator client helpers loaded\")\n",
    "\n"
   ],
   "id": "client",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Tree Expansion Algorithm\n",
    "\n",
    "### Algorithm Overview:\n",
    "\n",
    "This is the **core algorithm** that builds the complete execution tree by exploring all combinations of simultaneous Choice/Nature decisions.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Initialize**: Bootstrap simulator and setup BFS frontier\n",
    "2. **For each node in frontier**:\n",
    "   - Skip if already expanded\n",
    "   - Check if final state \u2192 mark done\n",
    "   - Get enabled stop transitions (decision points)\n",
    "   - **Generate all combinations** using cartesian product\n",
    "   - For each combination:\n",
    "     - Expand with specific choices\n",
    "     - Collect child nodes\n",
    "   - **Deduplicate** children by signature\n",
    "   - Update tree with unique children\n",
    "   - Add children to frontier\n",
    "3. **Continue** until frontier is empty\n",
    "\n",
    "### Complexity:\n",
    "\n",
    "- Time: O(N \u00d7 M^D) where:\n",
    "  - N = number of nodes in tree\n",
    "  - M = average alternatives per decision point\n",
    "  - D = average simultaneous decision points\n",
    "- Space: O(N) for tree storage\n",
    "\n",
    "### Debug Output:\n",
    "\n",
    "The algorithm prints detailed progress:\n",
    "- Decision points found per node\n",
    "- Number of combinations to explore\n",
    "- Each combination and its result\n",
    "- Unique vs duplicate children\n",
    "- Final statistics"
   ],
   "id": "algorithm_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_complete_execution_tree(client: SimulatorClient, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Build the complete execution tree by exploring ALL combinations.\n",
    "\n",
    "    This algorithm ensures that every possible execution path is explored by:\n",
    "    1. Identifying simultaneous decision points (enabled stop transitions)\n",
    "    2. Generating cartesian product of all alternatives\n",
    "    3. Exploring each combination and collecting unique children\n",
    "    4. Continuing BFS traversal until all nodes are expanded\n",
    "\n",
    "    Args:\n",
    "        client: SimulatorClient instance\n",
    "        parse_tree_payload: Parse tree from solver\n",
    "\n",
    "    Returns:\n",
    "        Complete shared state with fully expanded execution tree\n",
    "    \"\"\"\n",
    "    # Initialize simulator\n",
    "    shared_state = client.bootstrap(parse_tree_payload)\n",
    "    final_marking = shared_state[\"petri_net\"][\"final_marking\"]\n",
    "\n",
    "    # BFS state\n",
    "    expanded_nodes: set[str] = set()\n",
    "    frontier: deque[str] = deque([shared_state[\"execution_tree\"][\"root\"][\"id\"]])\n",
    "    queued_nodes: set[str] = set(frontier)\n",
    "    iteration = 0\n",
    "\n",
    "    # Main BFS loop\n",
    "    while frontier:\n",
    "        iteration += 1\n",
    "        node_id = frontier.popleft()\n",
    "        queued_nodes.discard(node_id)\n",
    "\n",
    "        # Skip already expanded nodes\n",
    "        if node_id in expanded_nodes:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n[{iteration}] Expanding node: {node_id}\")\n",
    "\n",
    "        # Get node from tree\n",
    "        node = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "        if not node:\n",
    "            print(f\"  \u2717 Node not found\")\n",
    "            continue\n",
    "\n",
    "        # Check if final state\n",
    "        if is_final_node(node, final_marking):\n",
    "            print(f\"  \u2713 Final marking reached\")\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "\n",
    "        # Check if already has children (from previous expansion)\n",
    "        if node.get(\"children\"):\n",
    "            children = node[\"children\"]\n",
    "            print(f\"  \u2139 Already has {len(children)} children - scheduling them\")\n",
    "            for child in children:\n",
    "                child_id = child.get(\"id\")\n",
    "                if not child_id or child_id in expanded_nodes or child_id in queued_nodes:\n",
    "                    continue\n",
    "                frontier.append(child_id)\n",
    "                queued_nodes.add(child_id)\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "\n",
    "        # Get enabled stop transitions (decision points)\n",
    "        snapshot = node.get(\"snapshot\", {})\n",
    "        status = snapshot.get(\"status\", {})\n",
    "        decisions = snapshot.get(\"decisions\", [])\n",
    "        choices = snapshot.get(\"choices\", [])\n",
    "\n",
    "        print(f\"  \u2022 Status: {status}\")\n",
    "        print(f\"  \u2022 Decisions made: {decisions}\")\n",
    "        print(f\"  \u2022 Choices made: {choices}\")\n",
    "\n",
    "        active_markings = None\n",
    "        marking = snapshot.get(\"marking\")\n",
    "        if isinstance(marking, dict):\n",
    "            active_markings = marking.get(\"active\")\n",
    "\n",
    "        if not active_markings and isinstance(status, dict):\n",
    "            active_markings = status.get(\"active_markings\") or status.get(\"active\")\n",
    "\n",
    "        if active_markings:\n",
    "            print(f\"  \u2022 Active markings: {active_markings}\")\n",
    "        else:\n",
    "            print(\"  \u2022 Active markings: None\")\n",
    "\n",
    "        stop_groups = get_stop_groups_from_status(status, active_markings=active_markings)\n",
    "\n",
    "        if active_markings:\n",
    "            active_labels = set(_collect_active_labels(active_markings))\n",
    "            if active_labels:\n",
    "                missing_labels = sorted(active_labels - set(stop_groups))\n",
    "                if missing_labels:\n",
    "                    print(f\"  \u26a0 Active marking labels without decisions: {missing_labels}\")\n",
    "\n",
    "        if not stop_groups:\n",
    "            print(f\"  \u2717 No decision points available in status (deadlock or final)\")\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "\n",
    "        # Display decision points found\n",
    "        print(f\"  \u2192 Found {len(stop_groups)} decision points: {list(stop_groups.keys())}\")\n",
    "        for label, trans_ids in stop_groups.items():\n",
    "            print(f\"     {label}: {len(trans_ids)} alternatives (IDs: {trans_ids})\")\n",
    "\n",
    "        # Generate ALL combinations using cartesian product\n",
    "        # Example: {C1: [t1, t2], N1: [t3, t4]} \u2192 [(t1,t3), (t1,t4), (t2,t3), (t2,t4)]\n",
    "        choice_lists = [trans_ids for trans_ids in stop_groups.values()]\n",
    "        all_combinations = list(product(*choice_lists))\n",
    "\n",
    "        print(f\"  \u2192 Total combinations to explore: {len(all_combinations)}\")\n",
    "\n",
    "        # Collect all unique children from all combinations\n",
    "        all_children: dict[tuple, Dict[str, Any]] = {}  # signature -> child_node\n",
    "\n",
    "        for combo_idx, combination in enumerate(all_combinations):\n",
    "            selected_choices = list(combination)\n",
    "            print(f\"    \u2022 Combination {combo_idx + 1}: {selected_choices}\")\n",
    "\n",
    "            try:\n",
    "                # Expand with this combination\n",
    "                temp_state = copy.deepcopy(shared_state)\n",
    "                response = client.expand_node(temp_state, node_id, choices=selected_choices)\n",
    "\n",
    "                # Get expanded node from response\n",
    "                temp_tree = response.get(\"execution_tree\", {})\n",
    "                expanded_node = get_node_by_id(temp_tree.get(\"root\", {}), node_id)\n",
    "\n",
    "                if expanded_node and expanded_node.get(\"children\"):\n",
    "                    for child in expanded_node[\"children\"]:\n",
    "                        # Use signature (impacts + probability) as unique key\n",
    "                        sig = node_signature(child)\n",
    "                        if sig not in all_children:\n",
    "                            branch = copy.deepcopy(child)\n",
    "                            all_children[sig] = branch\n",
    "                            child_id = branch.get(\"id\")\n",
    "                            print(f\"      \u2713 New branch (id={child_id}): impacts={branch['snapshot']['impacts']}, prob={branch['snapshot']['probability']}\")\n",
    "                        else:\n",
    "                            print(f\"      = Duplicate (already seen)\")\n",
    "                else:\n",
    "                    print(f\"      \u26a0 No children created\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      \u2717 Error: {e}\")\n",
    "\n",
    "        # Update node with ALL unique children\n",
    "        if all_children:\n",
    "            print(f\"  \u2713 Total unique children: {len(all_children)}\")\n",
    "            node_to_update = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "            if node_to_update:\n",
    "                children_list = []\n",
    "                for child in all_children.values():\n",
    "                    child_copy = copy.deepcopy(child)\n",
    "                    children_list.append(child_copy)\n",
    "                    child_id = child_copy.get(\"id\")\n",
    "                    if not child_id or child_id in expanded_nodes or child_id in queued_nodes:\n",
    "                        continue\n",
    "                    frontier.append(child_id)\n",
    "                    queued_nodes.add(child_id)\n",
    "\n",
    "                # Update tree\n",
    "                node_to_update[\"children\"] = children_list\n",
    "\n",
    "        expanded_nodes.add(node_id)\n",
    "\n",
    "    # Print final statistics\n",
    "    total_nodes = count_nodes(shared_state['execution_tree']['root'])\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"\u2713 EXPANSION COMPLETE\")\n",
    "    print(f\"  Iterations: {iteration}\")\n",
    "    print(f\"  Expanded nodes: {len(expanded_nodes)}\")\n",
    "    print(f\"  Total tree nodes: {total_nodes}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return shared_state\n",
    "\n",
    "print(\"\u2713 Expansion algorithm loaded\")\n",
    "\n",
    "\n"
   ],
   "id": "algorithm",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Complete Expansion\n",
    "\n",
    "Run the complete expansion algorithm.\n",
    "\n",
    "### Expected Output:\n",
    "\n",
    "You will see detailed progress for each node:\n",
    "- Decision points identified\n",
    "- Combinations being explored\n",
    "- Children created (unique vs duplicates)\n",
    "- Final tree statistics\n",
    "\n",
    "### Performance Notes:\n",
    "\n",
    "- Execution time depends on:\n",
    "  - Number of nodes in the process\n",
    "  - Number of parallel decision points\n",
    "  - Alternatives per decision point\n",
    "- For complex processes, this may take several minutes"
   ],
   "id": "execute_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "client = SimulatorClient()\n",
    "print(f\"\u2713 Simulator backend: {client.mode.upper()}\")\n",
    "shared_state_complete = build_complete_execution_tree(client, parse_tree)\n",
    "complete_root = shared_state_complete[\"execution_tree\"][\"root\"]\n",
    "print()\n",
    "print(f\"\u2713 Total nodes in complete tree: {count_nodes(complete_root)}\")\n",
    "\n"
   ],
   "id": "execute",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Execution Tree\n",
    "\n",
    "Generate a graphical representation of the complete execution tree.\n",
    "\n",
    "### Visualization Features:\n",
    "\n",
    "- Nodes show: impacts, probability, execution time\n",
    "- Edges represent execution transitions\n",
    "- Current node is highlighted\n",
    "- Final nodes are marked differently\n",
    "\n",
    "**Note**: For large trees, the visualization may be very large."
   ],
   "id": "visualize_tree_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    from paco.parser.dot.execution_tree import get_path_to_current_node, wrapper_execution_tree_to_dot\n",
    "except ImportError as exc:\n",
    "    print(f\"\u26a0\ufe0f Unable to import execution tree visualisation helpers: {exc}\")\n",
    "else:\n",
    "    from graphviz.backend.execute import ExecutableNotFound\n",
    "\n",
    "    execution_tree = shared_state_complete[\"execution_tree\"]\n",
    "    current_node_id = execution_tree.get(\"current_node\")\n",
    "    highlight_path = get_path_to_current_node(execution_tree.get(\"root\", {}), current_node_id) or []\n",
    "    dot_source = wrapper_execution_tree_to_dot(execution_tree.get(\"root\", {}), impacts_names, highlight_path)\n",
    "    try:\n",
    "        graph = graphviz.Source(dot_source, format=\"svg\")\n",
    "        display(graph)\n",
    "    except ExecutableNotFound as exc:\n",
    "        print(f\"\u26a0\ufe0f Unable to render execution tree locally: {exc}\")\n",
    "\n"
   ],
   "id": "visualize_tree",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save the complete execution tree to a JSON file for:\n",
    "- Further analysis\n",
    "- Pareto frontier computation\n",
    "- Performance evaluation\n",
    "- Documentation"
   ],
   "id": "export_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output_file = \"complete_execution_tree.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(shared_state_complete[\"execution_tree\"], f, indent=2)\n",
    "print(f\"\u2713 Execution tree exported to {output_file}\")"
   ],
   "id": "export",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a complete execution tree expansion algorithm that:\n",
    "\n",
    "### \u2705 Features:\n",
    "- **Complete Exploration**: All combinations of simultaneous decisions\n",
    "- **Correct Identification**: Uses Petri net stop transitions to find decision points\n",
    "- **Deduplication**: Differentiates nodes by impacts and probability\n",
    "- **BFS Traversal**: Systematic exploration of the entire tree\n",
    "- **Detailed Logging**: Progress tracking and statistics\n",
    "\n",
    "### \ud83d\udcca Use Cases:\n",
    "- Generate complete execution trees for BPMN processes\n",
    "- Compute Pareto frontiers of non-dominated solutions\n",
    "- Analyze process complexity and decision impact\n",
    "- Validate process correctness and completeness\n",
    "\n",
    "### \ud83d\udd27 Configuration:\n",
    "- Adjust `URL`, `SIMULATOR_PORT`, `SOLVER_PORT` for your environment\n",
    "- Modify BPMN file path as needed\n",
    "- Customize output file name\n",
    "\n",
    "### \ud83d\udcdd References:\n",
    "- BPMN 2.0 Specification\n",
    "- Petri Net theory for process modeling\n",
    "- Multi-objective optimization literature"
   ],
   "id": "summary"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}