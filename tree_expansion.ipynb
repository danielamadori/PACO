{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Execution Tree Expansion\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a **complete execution tree expansion algorithm** that explores all possible execution paths in a BPMN process by enumerating all combinations of simultaneous Choice and Nature nodes.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "When a BPMN process contains parallel execution branches with multiple decision points (Choice nodes) or probabilistic branches (Nature nodes), the execution tree must capture **all possible combinations** of choices across these simultaneous decision points.\n",
    "\n",
    "### Key Challenges:\n",
    "\n",
    "1. **Simultaneous Decisions**: Multiple Choice/Nature nodes can be enabled at the same time (parallel execution)\n",
    "2. **Combinatorial Explosion**: With N decision points having M alternatives each, we need to explore M^N combinations\n",
    "3. **Node Identification**: The simulator may assign the same ID to different execution paths, requiring differentiation by impacts and probability\n",
    "4. **Server Interface**: The server uses transitions with `stop=True` to represent decision points and expects a list of transition IDs as choices\n",
    "\n",
    "## Algorithm Design\n",
    "\n",
    "### Core Strategy:\n",
    "\n",
    "```\n",
    "For each node to expand:\n",
    "  1. Identify all enabled stop transitions (decision points)\n",
    "  2. Group transitions by label (representing Choice/Nature nodes)\n",
    "  3. Generate cartesian product of all alternatives\n",
    "  4. For each combination:\n",
    "     - Call simulator with specific choices\n",
    "     - Collect resulting child nodes\n",
    "  5. Deduplicate children by (impacts, probability) signature\n",
    "  6. Update tree with all unique children\n",
    "  7. Continue BFS traversal\n",
    "```\n",
    "\n",
    "### Example:\n",
    "\n",
    "If we have:\n",
    "- **C1** (Choice): 2 alternatives [FD, RD]\n",
    "- **N1** (Nature): 2 alternatives [HP, LP] with probabilities [0.2, 0.8]\n",
    "\n",
    "Both enabled simultaneously → **4 combinations** to explore:\n",
    "1. (FD, HP) → impacts=[X1, Y1], prob=0.2\n",
    "2. (FD, LP) → impacts=[X2, Y2], prob=0.8\n",
    "3. (RD, HP) → impacts=[X3, Y3], prob=0.2\n",
    "4. (RD, LP) → impacts=[X4, Y4], prob=0.8\n",
    "\n",
    "Each combination produces a unique child node in the execution tree."
   ],
   "id": "intro"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ],
   "id": "setup_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('simulator/src')\n",
    "sys.path.append('src')\n",
    "import copy\n",
    "from itertools import product\n",
    "from collections import deque\n",
    "from typing import Any, Dict, List, Optional\n",
    "import requests\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "from IPython.core.display import SVG\n",
    "from src.utils.env import IMPACTS_NAMES\n",
    "\n",
    "# Configuration\n",
    "URL = \"127.0.0.1\"\n",
    "SIMULATOR_PORT = 8001\n",
    "SOLVER_PORT = 8000\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}"
   ],
   "id": "imports",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BPMN Definition\n",
    "\n",
    "Load the BPMN process definition from JSON file. This contains:\n",
    "- Process structure (activities, gateways, flows)\n",
    "- Impact definitions (resources consumed)\n",
    "- Duration and cost information"
   ],
   "id": "load_bpmn_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open(\"bpmn_fig8_bound_135_15.json\", \"r\") as f:\n",
    "    bpmn_file = f.read()\n",
    "\n",
    "bpmn_definition = json.loads(bpmn_file)\n",
    "impacts_names = bpmn_definition.get(IMPACTS_NAMES, [])\n",
    "print(f\"Loaded BPMN: {bpmn_definition.get('expression', '')}\")\n",
    "print(f\"Impact dimensions: {impacts_names}\")"
   ],
   "id": "load_bpmn",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Parse Tree and Visualize BPMN\n",
    "\n",
    "The solver API converts the BPMN definition into:\n",
    "1. **BPMN visualization** - Graphical representation of the process\n",
    "2. **Parse tree** - Hierarchical structure for execution"
   ],
   "id": "parse_tree_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    # Create BPMN visualization\n",
    "    resp = requests.get(f\"http://{URL}:{SOLVER_PORT}/create_bpmn\", json={'bpmn': bpmn_definition}, headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    display(SVG(graphviz.Source(resp.json()['bpmn_dot']).pipe(format=\"svg\")))\n",
    "\n",
    "    # Create parse tree\n",
    "    resp = requests.get(f\"http://{URL}:{SOLVER_PORT}/create_parse_tree\", json={'bpmn': bpmn_definition}, headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    parse_tree = resp.json()['parse_tree']\n",
    "    print(\"✓ Parse tree created successfully\")\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP Error ({resp.status_code}):\", resp.json())"
   ],
   "id": "parse_tree",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "### Core Utilities:\n",
    "\n",
    "- **`get_node_by_id`**: Recursive tree traversal to find a node by ID\n",
    "- **`is_final_node`**: Check if a node represents the final marking (end state)\n",
    "- **`count_nodes`**: Count total nodes in the tree (for statistics)\n",
    "- **`get_stop_transitions`**: Identify enabled decision points from the Petri net\n",
    "- **`node_signature`**: Create unique fingerprint for nodes based on impacts and probability"
   ],
   "id": "utils_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_node_by_id(root: Dict[str, Any], node_id: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Find a node by its ID in the execution tree.\n",
    "    \n",
    "    Args:\n",
    "        root: Root node of the tree\n",
    "        node_id: ID of the node to find\n",
    "        \n",
    "    Returns:\n",
    "        Node dictionary if found, None otherwise\n",
    "    \"\"\"\n",
    "    if root.get(\"id\") == node_id:\n",
    "        return root\n",
    "    for child in root.get(\"children\", []):\n",
    "        result = get_node_by_id(child, node_id)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_final_node(node: Dict[str, Any], final_marking: Dict[str, Dict[str, float]]) -> bool:\n",
    "    \"\"\"Check if a node represents a final marking (end state).\n",
    "    \n",
    "    Args:\n",
    "        node: Node to check\n",
    "        final_marking: Expected final marking from Petri net\n",
    "        \n",
    "    Returns:\n",
    "        True if node is in final state\n",
    "    \"\"\"\n",
    "    marking = node.get(\"snapshot\", {}).get(\"marking\", {})\n",
    "    if not marking or not final_marking:\n",
    "        return False\n",
    "    for place_name, place_data in final_marking.items():\n",
    "        if marking.get(place_name, {}).get(\"token\", 0) != place_data.get(\"token\", 0):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def count_nodes(node: Dict[str, Any]) -> int:\n",
    "    \"\"\"Recursively count all nodes in the tree.\n",
    "    \n",
    "    Args:\n",
    "        node: Root node\n",
    "        \n",
    "    Returns:\n",
    "        Total number of nodes including subtrees\n",
    "    \"\"\"\n",
    "    total = 1\n",
    "    for child in node.get(\"children\", []):\n",
    "        total += count_nodes(child)\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_stop_transitions(petri_net: Dict[str, Any], marking: Dict[str, Any]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Get all enabled stop transitions, grouped by label.\n",
    "    \n",
    "    Stop transitions represent decision points (Choice/Nature nodes) in the process.\n",
    "    This function:\n",
    "    1. Filters transitions with stop=True\n",
    "    2. Checks which are enabled in the current marking\n",
    "    3. Groups them by label (representing the same decision point)\n",
    "    \n",
    "    Args:\n",
    "        petri_net: Petri net structure\n",
    "        marking: Current marking (token distribution)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping label -> [transition_ids]\n",
    "        Example: {'C1': ['t5', 't6'], 'N1': ['t7', 't8']}\n",
    "    \"\"\"\n",
    "    transitions = petri_net.get(\"transitions\", [])\n",
    "    enabled_stop = {}\n",
    "    \n",
    "    for trans in transitions:\n",
    "        if not trans.get('stop', False):\n",
    "            continue\n",
    "        \n",
    "        trans_id = trans.get('id')\n",
    "        trans_label = trans.get('label')\n",
    "        inputs = trans.get('inputs', [])\n",
    "        \n",
    "        # Check if transition is enabled (all input places have tokens)\n",
    "        enabled = True\n",
    "        for place_id in inputs:\n",
    "            if place_id not in marking or marking[place_id].get('token', 0) <= 0:\n",
    "                enabled = False\n",
    "                break\n",
    "        \n",
    "        if enabled:\n",
    "            if trans_label not in enabled_stop:\n",
    "                enabled_stop[trans_label] = []\n",
    "            enabled_stop[trans_label].append(trans_id)\n",
    "    \n",
    "    return enabled_stop\n",
    "\n",
    "\n",
    "def node_signature(node: Dict[str, Any]) -> tuple:\n",
    "    \"\"\"Create a unique signature for a node based on impacts and probability.\n",
    "    \n",
    "    Since the server may assign the same ID to different execution paths,\n",
    "    we need to differentiate nodes by their actual state (impacts) and\n",
    "    probability (for Nature nodes).\n",
    "    \n",
    "    Args:\n",
    "        node: Node to fingerprint\n",
    "        \n",
    "    Returns:\n",
    "        Tuple (impacts, probability) for use as dictionary key\n",
    "    \"\"\"\n",
    "    impacts = tuple(node['snapshot']['impacts'])\n",
    "    prob = node['snapshot']['probability']\n",
    "    return (impacts, prob)\n",
    "\n",
    "print(\"✓ Utility functions loaded\")"
   ],
   "id": "utils",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimulatorClient Class\n",
    "\n",
    "Client wrapper for the simulator API.\n",
    "\n",
    "### Key Methods:\n",
    "\n",
    "- **`bootstrap`**: Initialize simulation with parse tree\n",
    "- **`expand_node`**: Expand a specific node with given choices\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "- The server operates on `execution_tree.current_node`\n",
    "- Choices are passed as a list of transition IDs\n",
    "- Each call returns updated state (petri_net, execution_tree, etc.)"
   ],
   "id": "client_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SimulatorClient:\n",
    "    \"\"\"Client for interacting with the simulator API.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = f\"http://{URL}:{SIMULATOR_PORT}/\") -> None:\n",
    "        self.base_url = base_url.rstrip(\"/\") + \"/\"\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a request to the simulator.\n",
    "        \n",
    "        Args:\n",
    "            payload: Request payload (bpmn, petri_net, execution_tree, choices)\n",
    "            \n",
    "        Returns:\n",
    "            Response dictionary with updated state\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If server returns an error\n",
    "        \"\"\"\n",
    "        response = self.session.post(self.base_url + \"execute\", headers=HEADERS, json=payload, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if \"error\" in data:\n",
    "            raise RuntimeError(f\"Simulator error: {data['error']}\")\n",
    "        return data\n",
    "\n",
    "    def bootstrap(self, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Initialize the simulator with a parse tree.\n",
    "        \n",
    "        Args:\n",
    "            parse_tree_payload: Parse tree from solver\n",
    "            \n",
    "        Returns:\n",
    "            Initial state (bpmn, petri_net, execution_tree)\n",
    "        \"\"\"\n",
    "        payload = {\"bpmn\": parse_tree_payload}\n",
    "        return self.execute(payload)\n",
    "\n",
    "    def expand_node(\n",
    "        self,\n",
    "        shared_state: Dict[str, Any],\n",
    "        node_id: str,\n",
    "        *,\n",
    "        choices: Optional[List[str]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Expand a specific node with given choices.\n",
    "        \n",
    "        The server operates on execution_tree.current_node, so we:\n",
    "        1. Copy the shared state\n",
    "        2. Set current_node to the node we want to expand\n",
    "        3. Send the request with optional choices\n",
    "        \n",
    "        Args:\n",
    "            shared_state: Current simulation state\n",
    "            node_id: ID of node to expand\n",
    "            choices: Optional list of transition IDs representing choices\n",
    "            \n",
    "        Returns:\n",
    "            Updated state with expanded tree\n",
    "        \"\"\"\n",
    "        exec_tree = copy.deepcopy(shared_state[\"execution_tree\"])\n",
    "        exec_tree[\"current_node\"] = node_id\n",
    "        \n",
    "        request_payload = {\n",
    "            \"bpmn\": shared_state[\"bpmn\"],\n",
    "            \"petri_net\": shared_state[\"petri_net\"],\n",
    "            \"execution_tree\": exec_tree,\n",
    "        }\n",
    "        if choices is not None:\n",
    "            request_payload[\"choices\"] = list(choices)\n",
    "        \n",
    "        response = self.execute(request_payload)\n",
    "        return response\n",
    "\n",
    "print(\"✓ SimulatorClient class loaded\")"
   ],
   "id": "client",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Tree Expansion Algorithm\n",
    "\n",
    "### Algorithm Overview:\n",
    "\n",
    "This is the **core algorithm** that builds the complete execution tree by exploring all combinations of simultaneous Choice/Nature decisions.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Initialize**: Bootstrap simulator and setup BFS frontier\n",
    "2. **For each node in frontier**:\n",
    "   - Skip if already expanded\n",
    "   - Check if final state → mark done\n",
    "   - Get enabled stop transitions (decision points)\n",
    "   - **Generate all combinations** using cartesian product\n",
    "   - For each combination:\n",
    "     - Expand with specific choices\n",
    "     - Collect child nodes\n",
    "   - **Deduplicate** children by signature\n",
    "   - Update tree with unique children\n",
    "   - Add children to frontier\n",
    "3. **Continue** until frontier is empty\n",
    "\n",
    "### Complexity:\n",
    "\n",
    "- Time: O(N × M^D) where:\n",
    "  - N = number of nodes in tree\n",
    "  - M = average alternatives per decision point\n",
    "  - D = average simultaneous decision points\n",
    "- Space: O(N) for tree storage\n",
    "\n",
    "### Debug Output:\n",
    "\n",
    "The algorithm prints detailed progress:\n",
    "- Decision points found per node\n",
    "- Number of combinations to explore\n",
    "- Each combination and its result\n",
    "- Unique vs duplicate children\n",
    "- Final statistics"
   ],
   "id": "algorithm_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_complete_execution_tree(client: SimulatorClient, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Build the complete execution tree by exploring ALL combinations.\n",
    "\n",
    "    This algorithm ensures that every possible execution path is explored by:\n",
    "    1. Identifying simultaneous decision points (enabled stop transitions)\n",
    "    2. Generating cartesian product of all alternatives\n",
    "    3. Exploring each combination and collecting unique children\n",
    "    4. Continuing BFS traversal until all nodes are expanded\n",
    "\n",
    "    Args:\n",
    "        client: SimulatorClient instance\n",
    "        parse_tree_payload: Parse tree from solver\n",
    "\n",
    "    Returns:\n",
    "        Complete shared state with fully expanded execution tree\n",
    "    \"\"\"\n",
    "    # Initialize simulator\n",
    "    shared_state = client.bootstrap(parse_tree_payload)\n",
    "    final_marking = shared_state[\"petri_net\"][\"final_marking\"]\n",
    "\n",
    "    # BFS state\n",
    "    expanded_nodes = set()\n",
    "    frontier: deque[str] = deque([shared_state[\"execution_tree\"][\"root\"][\"id\"]])\n",
    "    iteration = 0\n",
    "\n",
    "    # Main BFS loop\n",
    "    while frontier:\n",
    "        iteration += 1\n",
    "        node_id = frontier.popleft()\n",
    "\n",
    "        # Skip already expanded nodes\n",
    "        if node_id in expanded_nodes:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n[{iteration}] Expanding node: {node_id}\")\n",
    "\n",
    "        # Get node from tree\n",
    "        node = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "        if not node:\n",
    "            print(f\"  ✗ Node not found\")\n",
    "            continue\n",
    "\n",
    "        # Check if final state\n",
    "        if is_final_node(node, final_marking):\n",
    "            print(f\"  ✓ Final marking reached\")\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "\n",
    "        # Check if already has children (from previous expansion)\n",
    "        if node.get(\"children\"):\n",
    "            children = node[\"children\"]\n",
    "            print(f\"  ℹ Already has {len(children)} children - scheduling them\")\n",
    "            for child in children:\n",
    "                if child.get(\"id\") not in expanded_nodes:\n",
    "                    frontier.append(child[\"id\"])\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "\n",
    "        # Get enabled stop transitions (decision points)\n",
    "        snapshot = node.get(\"snapshot\", {})\n",
    "        status = snapshot.get(\"status\", {})\n",
    "        decisions = snapshot.get(\"decisions\", [])\n",
    "        choices = snapshot.get(\"choices\", [])\n",
    "\n",
    "        print(f\"  • Status: {status}\")\n",
    "        print(f\"  • Decisions made: {decisions}\")\n",
    "        print(f\"  • Choices made: {choices}\")\n",
    "\n",
    "        marking = snapshot.get(\"marking\", {})\n",
    "        stop_groups = get_stop_transitions(shared_state[\"petri_net\"], marking)\n",
    "\n",
    "        if not stop_groups:\n",
    "            print(f\"  ✗ No stop transitions (deadlock or final)\")\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "\n",
    "        # Display decision points found\n",
    "        print(f\"  → Found {len(stop_groups)} decision points: {list(stop_groups.keys())}\")\n",
    "        for label, trans_ids in stop_groups.items():\n",
    "            print(f\"     {label}: {len(trans_ids)} alternatives (IDs: {trans_ids})\")\n",
    "\n",
    "        # Generate ALL combinations using cartesian product\n",
    "        # Example: {C1: [t1, t2], N1: [t3, t4]} → [(t1,t3), (t1,t4), (t2,t3), (t2,t4)]\n",
    "        choice_lists = [trans_ids for trans_ids in stop_groups.values()]\n",
    "        all_combinations = list(product(*choice_lists))\n",
    "\n",
    "        print(f\"  → Total combinations to explore: {len(all_combinations)}\")\n",
    "\n",
    "        # Collect all unique children from all combinations\n",
    "        all_children = {}  # signature -> child_node\n",
    "\n",
    "        for combo_idx, combination in enumerate(all_combinations):\n",
    "            choices = list(combination)\n",
    "            print(f\"    • Combination {combo_idx + 1}: {choices}\")\n",
    "\n",
    "            try:\n",
    "                # Expand with this combination\n",
    "                temp_state = copy.deepcopy(shared_state)\n",
    "                response = client.expand_node(temp_state, node_id, choices=choices)\n",
    "\n",
    "                # Get expanded node from response\n",
    "                temp_tree = response.get(\"execution_tree\", {})\n",
    "                expanded_node = get_node_by_id(temp_tree.get(\"root\", {}), node_id)\n",
    "\n",
    "                if expanded_node and expanded_node.get(\"children\"):\n",
    "                    for child in expanded_node[\"children\"]:\n",
    "                        # Use signature (impacts + probability) as unique key\n",
    "                        sig = node_signature(child)\n",
    "                        if sig not in all_children:\n",
    "                            all_children[sig] = copy.deepcopy(child)\n",
    "                            print(f\"      ✓ New branch: impacts={child['snapshot']['impacts']}, prob={child['snapshot']['probability']}\")\n",
    "                        else:\n",
    "                            print(f\"      = Duplicate (already seen)\")\n",
    "                else:\n",
    "                    print(f\"      ⚠ No children created\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      ✗ Error: {e}\")\n",
    "\n",
    "        # Update node with ALL unique children\n",
    "        if all_children:\n",
    "            print(f\"  ✓ Total unique children: {len(all_children)}\")\n",
    "            node_to_update = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "            if node_to_update:\n",
    "                # Reassign IDs to children to ensure uniqueness\n",
    "                children_list = []\n",
    "                for idx, child in enumerate(all_children.values()):\n",
    "                    child_copy = copy.deepcopy(child)\n",
    "                    # Create unique ID: parent_id + index\n",
    "                    child_copy['id'] = f\"{node_id}_{idx}\"\n",
    "                    children_list.append(child_copy)\n",
    "                    # Add to frontier for further expansion\n",
    "                    frontier.append(child_copy['id'])\n",
    "\n",
    "                # Update tree\n",
    "                node_to_update[\"children\"] = children_list\n",
    "\n",
    "        expanded_nodes.add(node_id)\n",
    "\n",
    "    # Print final statistics\n",
    "    total_nodes = count_nodes(shared_state['execution_tree']['root'])\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"✓ EXPANSION COMPLETE\")\n",
    "    print(f\"  Iterations: {iteration}\")\n",
    "    print(f\"  Expanded nodes: {len(expanded_nodes)}\")\n",
    "    print(f\"  Total tree nodes: {total_nodes}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return shared_state\n",
    "\n",
    "print(\"✓ Expansion algorithm loaded\")"
   ],
   "id": "algorithm",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Complete Expansion\n",
    "\n",
    "Run the complete expansion algorithm.\n",
    "\n",
    "### Expected Output:\n",
    "\n",
    "You will see detailed progress for each node:\n",
    "- Decision points identified\n",
    "- Combinations being explored\n",
    "- Children created (unique vs duplicates)\n",
    "- Final tree statistics\n",
    "\n",
    "### Performance Notes:\n",
    "\n",
    "- Execution time depends on:\n",
    "  - Number of nodes in the process\n",
    "  - Number of parallel decision points\n",
    "  - Alternatives per decision point\n",
    "- For complex processes, this may take several minutes"
   ],
   "id": "execute_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "client = SimulatorClient()\n",
    "shared_state_complete = build_complete_execution_tree(client, parse_tree)\n",
    "complete_root = shared_state_complete[\"execution_tree\"][\"root\"]\n",
    "print(f\"\\n✓ Total nodes in complete tree: {count_nodes(complete_root)}\")"
   ],
   "id": "execute",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Execution Tree\n",
    "\n",
    "Generate a graphical representation of the complete execution tree.\n",
    "\n",
    "### Visualization Features:\n",
    "\n",
    "- Nodes show: impacts, probability, execution time\n",
    "- Edges represent execution transitions\n",
    "- Current node is highlighted\n",
    "- Final nodes are marked differently\n",
    "\n",
    "**Note**: For large trees, the visualization may be very large."
   ],
   "id": "visualize_tree_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from paco.parser.dot.execution_tree import get_path_to_current_node, wrapper_execution_tree_to_dot\n",
    "\n",
    "execution_tree = shared_state_complete[\"execution_tree\"]\n",
    "current_node_id = execution_tree.get(\"current_node\")\n",
    "highlight_path = get_path_to_current_node(execution_tree.get(\"root\", {}), current_node_id) or []\n",
    "dot_source = wrapper_execution_tree_to_dot(execution_tree.get(\"root\", {}), impacts_names, highlight_path)\n",
    "graph = graphviz.Source(dot_source, format=\"svg\")\n",
    "display(graph)"
   ],
   "id": "visualize_tree",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save the complete execution tree to a JSON file for:\n",
    "- Further analysis\n",
    "- Pareto frontier computation\n",
    "- Performance evaluation\n",
    "- Documentation"
   ],
   "id": "export_header"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "output_file = \"complete_execution_tree.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(shared_state_complete[\"execution_tree\"], f, indent=2)\n",
    "print(f\"✓ Execution tree exported to {output_file}\")"
   ],
   "id": "export",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a complete execution tree expansion algorithm that:\n",
    "\n",
    "### ✅ Features:\n",
    "- **Complete Exploration**: All combinations of simultaneous decisions\n",
    "- **Correct Identification**: Uses Petri net stop transitions to find decision points\n",
    "- **Deduplication**: Differentiates nodes by impacts and probability\n",
    "- **BFS Traversal**: Systematic exploration of the entire tree\n",
    "- **Detailed Logging**: Progress tracking and statistics\n",
    "\n",
    "### 📊 Use Cases:\n",
    "- Generate complete execution trees for BPMN processes\n",
    "- Compute Pareto frontiers of non-dominated solutions\n",
    "- Analyze process complexity and decision impact\n",
    "- Validate process correctness and completeness\n",
    "\n",
    "### 🔧 Configuration:\n",
    "- Adjust `URL`, `SIMULATOR_PORT`, `SOLVER_PORT` for your environment\n",
    "- Modify BPMN file path as needed\n",
    "- Customize output file name\n",
    "\n",
    "### 📝 References:\n",
    "- BPMN 2.0 Specification\n",
    "- Petri Net theory for process modeling\n",
    "- Multi-objective optimization literature"
   ],
   "id": "summary"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
