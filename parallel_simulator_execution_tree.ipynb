{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel execution tree expansion with the simulator API\n",
    "\n",
    "Questo notebook mostra come usare le API REST del simulatore per generare un execution tree in parallelo. L'obiettivo è mantenere l'albero condiviso tra i thread, delegando la creazione dei nodi al simulatore e rispettando il vincolo che ogni thread che genera figli con una natura attiva continui immediatamente l'espansione di quella sottostruttura.\n"
   ],
   "id": "2f35f01d9b3e0ed4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('simulator/src')\n",
    "sys.path.append('src')\n",
    "import os\n",
    "import threading\n",
    "import queue\n",
    "import copy\n",
    "from collections import deque\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
    "import requests\n",
    "import graphviz\n",
    "import requests\n",
    "from IPython.display import display\n",
    "from src.utils.env import IMPACTS_NAMES\n",
    "from dot import wrapper_execution_tree_to_dot, get_path_to_current_node\n",
    "\n",
    "\n",
    "URL = \"127.0.0.1\"\n",
    "SIMULATOR_PORT = 8001\n",
    "SOLVER_PORT = 8000\n",
    "\n",
    "SIMULATOR_SERVER = os.getenv(\"SIMULATOR_SERVER\", \"http://127.0.0.1:8001/\")\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}"
   ],
   "id": "3f14f1e09726e85d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.core.display import SVG\n",
    "\n",
    "with open(\"bpmn_fig8_bound_135_15.json\", \"r\") as f:\n",
    "    bpmn_file = f.read()\n",
    "\n",
    "bpmn_definition = json.loads(bpmn_file)\n",
    "impacts_names = bpmn_definition.get(IMPACTS_NAMES, [])\n",
    "\n",
    "try:\n",
    "    resp = requests.get(f\"http://{URL}:{SOLVER_PORT}/create_bpmn\", json={'bpmn': bpmn_definition},  headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    display(SVG(graphviz.Source(resp.json()['bpmn_dot']).pipe(format=\"svg\")))\n",
    "\n",
    "    resp = requests.get(f\"http://{URL}:{SOLVER_PORT}/create_parse_tree\", json={'bpmn': bpmn_definition},  headers=HEADERS)\n",
    "    resp.raise_for_status()\n",
    "    parse_tree = resp.json()['parse_tree']\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    print(f\"HTTP Error ({resp.status_code}):\", resp.json())"
   ],
   "id": "e9046e4a9395785c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bpmn_definition"
   ],
   "id": "d05c063b344b3d45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'normalize_parse_tree' not in globals():\n",
    "    def normalize_parse_tree(data):\n",
    "        \"\"\"Return a copy of the parse tree with normalized node types.\"\"\"\n",
    "        if isinstance(data, str):\n",
    "            tree_data = json.loads(data)\n",
    "        else:\n",
    "            tree_data = copy.deepcopy(data)\n",
    "\n",
    "        def _normalize(node):\n",
    "            if isinstance(node, dict):\n",
    "                node_type = node.get('type')\n",
    "                if isinstance(node_type, str):\n",
    "                    node['type'] = node_type.capitalize()\n",
    "                for key in ('sx_child', 'dx_child'):\n",
    "                    child = node.get(key)\n",
    "                    if isinstance(child, (dict, list)):\n",
    "                        _normalize(child)\n",
    "                transitions = node.get('transitions')\n",
    "                if isinstance(transitions, dict):\n",
    "                    for child in transitions.values():\n",
    "                        if isinstance(child, (dict, list)):\n",
    "                            _normalize(child)\n",
    "                children = node.get('children')\n",
    "                if isinstance(children, list):\n",
    "                    for child in children:\n",
    "                        if isinstance(child, (dict, list)):\n",
    "                            _normalize(child)\n",
    "            elif isinstance(node, list):\n",
    "                for item in node:\n",
    "                    if isinstance(item, (dict, list)):\n",
    "                        _normalize(item)\n",
    "            return node\n",
    "\n",
    "        return _normalize(tree_data)\n",
    "\n"
   ],
   "id": "cf17cac1604c7d21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BPMN\n",
   "id": "83a26e9ec2e9e218"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "request_json = { \"bpmn\": parse_tree }\n",
    "\n",
    "response = requests.post(f\"http://{URL}:{SIMULATOR_PORT}/execute\", headers=HEADERS, json=request_json)\n",
    "response_json = response.json()\n",
    "\n",
    "bpmn = response_json['bpmn']\n",
    "petri_net = response_json['petri_net']\n",
    "petri_net_dot = response_json['petri_net_dot']\n",
    "execution_tree = response_json['execution_tree']\n"
   ],
   "id": "41d6ff8628a690c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "execution_tree",
   "id": "65098750c52130af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from dot import get_active_region_by_pn, wrap_to_dot\n",
    "marking = {\"21\": {\"token\": 1}, \"7\": {\"token\": 1}}\n",
    "\n",
    "active_region_by_pn = get_active_region_by_pn(petri_net, marking)\n",
    "dot = wrap_to_dot(bpmn, impacts_names, active_region_by_pn)\n",
    "graph = graphviz.Source(dot, format=\"svg\")\n",
    "\n",
    "display(graph)"
   ],
   "id": "4b4e3e0b20e1ee81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker\n",
    "\n",
    "Use endpoint `/execute`. Accetta un payload JSON e restituisce strutture pronte da reinserire nell'albero condiviso.\n"
   ],
   "id": "68f3e2d2a656521"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Worker:\n",
    "    def __init__(self, base_url: str = SIMULATOR_SERVER, session: Optional[requests.Session] = None) -> None:\n",
    "        self.base_url = base_url.rstrip(\"/\") + \"/\"\n",
    "        self.session = session or requests.Session()\n",
    "\n",
    "    def execute(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        response = self.session.post(self.base_url + \"execute\", headers=HEADERS, json=payload, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if \"error\" in data:\n",
    "            raise RuntimeError(f\"Worker error: {data['error']}\")\n",
    "        return data\n",
    "\n",
    "    def bootstrap(self, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        payload = {\"bpmn\": parse_tree_payload}\n",
    "        return self.execute(payload)\n",
    "\n",
    "    def expand_node(\n",
    "        self,\n",
    "        shared_state: Dict[str, Any],\n",
    "        node_id: str,\n",
    "        *,\n",
    "        choices: Optional[List[str]] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Expand a node by calling the simulator /execute endpoint.\n",
    "        The server works on execution_tree.current_node, so we update it before calling.\n",
    "        \"\"\"\n",
    "        # Clone the execution tree and set current_node to the target node\n",
    "        exec_tree = copy.deepcopy(shared_state[\"execution_tree\"])\n",
    "        exec_tree[\"current_node\"] = node_id\n",
    "        \n",
    "        request_payload = {\n",
    "            \"bpmn\": shared_state[\"bpmn\"],\n",
    "            \"petri_net\": shared_state[\"petri_net\"],\n",
    "            \"execution_tree\": exec_tree,\n",
    "        }\n",
    "        if choices is not None:\n",
    "            request_payload[\"choices\"] = list(choices)\n",
    "        \n",
    "        response = self.execute(request_payload)\n",
    "        return response"
   ],
   "id": "a1aa4bded7906c23",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SimulatorClient(Worker):\n",
    "    \"\"\"Lightweight client that reuses the Worker implementation.\"\"\"\n",
    "    pass\n"
   ],
   "id": "4bdd34ab56bd2a8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilità per navigare l'albero\n",
    "\n",
    "Funzioni di supporto per contare i nodi, estrarre percorsi e aggiornare porzioni dell'albero senza blocchi globali.\n"
   ],
   "id": "b552db9d28101d68"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def iter_leaf_nodes(node: Dict[str, Any], path: Tuple[str, ...] = ()) -> Iterable[Tuple[str, ...]]:\n",
    "    \"\"\"Return paths to all leaf nodes (nodes without children).\"\"\"\n",
    "    children = node.get(\"children\", [])\n",
    "    if not children:\n",
    "        yield path\n",
    "    else:\n",
    "        for idx, child in enumerate(children):\n",
    "            yield from iter_leaf_nodes(child, path + (str(idx),))\n",
    "\n",
    "\n",
    "def get_node_at_path(root: Dict[str, Any], path: Tuple[str, ...]) -> Dict[str, Any]:\n",
    "    \"\"\"Follow the path and return the dictionary corresponding to the node.\"\"\"\n",
    "    node = root\n",
    "    for key in path:\n",
    "        children = node.get(\"children\", [])\n",
    "        node = children[int(key)]\n",
    "    return node\n",
    "\n",
    "\n",
    "def get_node_by_id(root: Dict[str, Any], node_id: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Find a node by its ID in the tree.\"\"\"\n",
    "    if root.get(\"id\") == node_id:\n",
    "        return root\n",
    "    for child in root.get(\"children\", []):\n",
    "        result = get_node_by_id(child, node_id)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_final_node(node: Dict[str, Any], final_marking: Dict[str, Dict[str, float]]) -> bool:\n",
    "    \"\"\"Check if a node represents a final marking.\"\"\"\n",
    "    marking = node.get(\"snapshot\", {}).get(\"marking\", {})\n",
    "    if not marking or not final_marking:\n",
    "        return False\n",
    "    # Compare markings (simplified check)\n",
    "    for place_name, place_data in final_marking.items():\n",
    "        if marking.get(place_name, {}).get(\"token\", 0) != place_data.get(\"token\", 0):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def count_nodes(node: Dict[str, Any]) -> int:\n",
    "    \"\"\"Recursively count the nodes stored in the tree.\"\"\"\n",
    "    total = 1\n",
    "    for child in node.get(\"children\", []):\n",
    "        total += count_nodes(child)\n",
    "    return total\n",
    "\n",
    "\n",
    "def clone_with_children(node: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Clone the tree (already uses 'children' format from server).\"\"\"\n",
    "    if not node:\n",
    "        return {}\n",
    "    \n",
    "    cloned = {key: copy.deepcopy(value) for key, value in node.items() if key != \"children\"}\n",
    "    children = [clone_with_children(child) for child in node.get(\"children\", [])]\n",
    "    cloned[\"children\"] = children\n",
    "    return cloned"
   ],
   "id": "826dd80a91b043bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler parallelo\n",
    "\n",
    "`ParallelExecutionTreeBuilder` coordina i thread e garantisce che i nodi figli con nature attive vengano espansi immediatamente dallo stesso worker. Ogni nodo dell'albero possiede un proprio lock per evitare un collo di bottiglia globale durante l'inserimento dei figli.\n"
   ],
   "id": "48d83447f124127a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ParallelExecutionTreeBuilder:\n",
    "    \"\"\"Expand an execution tree by driving the simulator in parallel.\"\"\"\n",
    "\n",
    "    def __init__(self, client: SimulatorClient, max_workers: int = 1) -> None:\n",
    "        if max_workers < 1:\n",
    "            raise ValueError(\"max_workers must be >= 1\")\n",
    "        self.client = client\n",
    "        self.max_workers = max_workers\n",
    "        self._queue: \"queue.Queue[str]\" = queue.Queue()  # Queue of node IDs to expand\n",
    "        self._node_locks: Dict[str, threading.Lock] = {}\n",
    "        self._locks_guard = threading.Lock()\n",
    "        self._stop_event = threading.Event()\n",
    "        self._expanded_nodes: set = set()  # Track expanded nodes\n",
    "        self._tree_lock = threading.Lock()  # Global lock for tree updates\n",
    "\n",
    "    def _lock_for(self, node_id: str) -> threading.Lock:\n",
    "        with self._locks_guard:\n",
    "            lock = self._node_locks.get(node_id)\n",
    "            if lock is None:\n",
    "                lock = threading.Lock()\n",
    "                self._node_locks[node_id] = lock\n",
    "            return lock\n",
    "\n",
    "    def _enqueue_initial_frontier(self, tree_root: Dict[str, Any]) -> None:\n",
    "        # Always start by expanding the root node\n",
    "        root_id = tree_root.get(\"id\", \"0\")\n",
    "        self._queue.put(root_id)\n",
    "\n",
    "    def _schedule_children(self, node_id: str) -> None:\n",
    "        \"\"\"Find the node in the tree and schedule its children for expansion.\"\"\"\n",
    "        with self._tree_lock:\n",
    "            node = get_node_by_id(self._shared_tree[\"execution_tree\"][\"root\"], node_id)\n",
    "            if not node:\n",
    "                return\n",
    "            \n",
    "            children = node.get(\"children\", [])\n",
    "            for child in children:\n",
    "                child_id = child.get(\"id\")\n",
    "                if child_id and child_id not in self._expanded_nodes:\n",
    "                    # Check if it's a final node\n",
    "                    if not is_final_node(child, self._shared_tree[\"petri_net\"][\"final_marking\"]):\n",
    "                        self._queue.put(child_id)\n",
    "\n",
    "    def _expand_node(self, node_id: str) -> None:\n",
    "        if self._stop_event.is_set():\n",
    "            return\n",
    "\n",
    "        # Check if already expanded\n",
    "        with self._locks_guard:\n",
    "            if node_id in self._expanded_nodes:\n",
    "                return\n",
    "            self._expanded_nodes.add(node_id)\n",
    "        \n",
    "        lock = self._lock_for(node_id)\n",
    "        with lock:\n",
    "            try:\n",
    "                # Check if node already has children\n",
    "                with self._tree_lock:\n",
    "                    node = get_node_by_id(self._shared_tree[\"execution_tree\"][\"root\"], node_id)\n",
    "                    if node and node.get(\"children\"):\n",
    "                        # Already expanded, just schedule children\n",
    "                        self._schedule_children(node_id)\n",
    "                        return\n",
    "                \n",
    "                # Expand with default choices - server creates ALL children for natures\n",
    "                response = self.client.expand_node(self._shared_tree, node_id, choices=[])\n",
    "                \n",
    "                # Update shared tree with response\n",
    "                with self._tree_lock:\n",
    "                    if \"execution_tree\" in response:\n",
    "                        self._shared_tree[\"execution_tree\"] = response[\"execution_tree\"]\n",
    "                    if \"petri_net\" in response:\n",
    "                        self._shared_tree[\"petri_net\"] = response[\"petri_net\"]\n",
    "                    if \"petri_net_dot\" in response:\n",
    "                        self._shared_tree[\"petri_net_dot\"] = response[\"petri_net_dot\"]\n",
    "                    if \"bpmn\" in response:\n",
    "                        self._shared_tree[\"bpmn\"] = response[\"bpmn\"]\n",
    "                \n",
    "                # Schedule ALL children for expansion\n",
    "                self._schedule_children(node_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Error expanding node {node_id}: {e}\")\n",
    "\n",
    "    def _worker(self) -> None:\n",
    "        while not self._stop_event.is_set():\n",
    "            try:\n",
    "                node_id = self._queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                self._expand_node(node_id)\n",
    "            finally:\n",
    "                self._queue.task_done()\n",
    "\n",
    "    def build(self, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        bootstrap = self.client.bootstrap(parse_tree_payload)\n",
    "        self._shared_tree = {\n",
    "            \"bpmn\": bootstrap[\"bpmn\"],\n",
    "            \"petri_net\": bootstrap[\"petri_net\"],\n",
    "            \"petri_net_dot\": bootstrap[\"petri_net_dot\"],\n",
    "            \"execution_tree\": bootstrap[\"execution_tree\"],\n",
    "        }\n",
    "        self._enqueue_initial_frontier(self._shared_tree[\"execution_tree\"][\"root\"])\n",
    "        \n",
    "        workers: List[threading.Thread] = []\n",
    "        for idx in range(self.max_workers):\n",
    "            t = threading.Thread(target=self._worker, name=f\"tree-worker-{idx}\", daemon=True)\n",
    "            t.start()\n",
    "            workers.append(t)\n",
    "        \n",
    "        self._queue.join()\n",
    "        self._stop_event.set()\n",
    "        \n",
    "        for t in workers:\n",
    "            t.join()\n",
    "        \n",
    "        return self._shared_tree\n",
    ""
   ],
   "id": "bcba12abee72cfd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo di espansione completa\n",
    "\n",
    "Questo algoritmo espande ricorsivamente tutte le transizioni pendenti sfruttando le API del simulatore fino a saturare l'intero execution tree.\n"
   ],
   "id": "dffc3fc2c85c7bb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_complete_execution_tree(client: SimulatorClient, parse_tree_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Espande TUTTO l'albero provando TUTTE le transizioni abilitate.\"\"\"\n",
    "    shared_state = client.bootstrap(parse_tree_payload)\n",
    "    final_marking = shared_state[\"petri_net\"][\"final_marking\"]\n",
    "    \n",
    "    expanded_nodes = set()\n",
    "    frontier: deque[str] = deque([shared_state[\"execution_tree\"][\"root\"][\"id\"]])\n",
    "    iteration = 0\n",
    "    \n",
    "    def get_enabled_transitions(node_marking, petri_net):\n",
    "        \"\"\"Ottiene tutte le transizioni abilitate dal marking.\"\"\"\n",
    "        enabled = []\n",
    "        transitions = petri_net.get(\"transitions\", [])\n",
    "        \n",
    "        if isinstance(transitions, dict):\n",
    "            trans_items = transitions.items()\n",
    "        else:\n",
    "            trans_items = [(t.get(\"name\", f\"t_{i}\"), t) for i, t in enumerate(transitions)]\n",
    "        \n",
    "        for trans_name, trans_data in trans_items:\n",
    "            can_fire = True\n",
    "            for place in trans_data.get(\"inputs\", []):\n",
    "                if node_marking.get(place, {}).get(\"token\", 0) <= 0:\n",
    "                    can_fire = False\n",
    "                    break\n",
    "            if can_fire:\n",
    "                enabled.append(trans_name)\n",
    "        return enabled\n",
    "    \n",
    "    while frontier:\n",
    "        iteration += 1\n",
    "        node_id = frontier.popleft()\n",
    "        \n",
    "        if node_id in expanded_nodes:\n",
    "            continue\n",
    "            \n",
    "        print(f\"[{iteration}] Node: {node_id}\")\n",
    "        \n",
    "        node = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "        if not node:\n",
    "            print(f\"  ✗ Not found\")\n",
    "            continue\n",
    "        \n",
    "        if is_final_node(node, final_marking):\n",
    "            print(f\"  ✓ Final node\")\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        # Se ha già figli, mettili in coda\n",
    "        if node.get(\"children\"):\n",
    "            children = node[\"children\"]\n",
    "            print(f\"  → Has {len(children)} children\")\n",
    "            for child in children:\n",
    "                if child[\"id\"] not in expanded_nodes:\n",
    "                    frontier.append(child[\"id\"])\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        # Espansione: identifica transizioni abilitate\n",
    "        marking = node.get(\"snapshot\", {}).get(\"marking\", {})\n",
    "        enabled = get_enabled_transitions(marking, shared_state[\"petri_net\"])\n",
    "        \n",
    "        if not enabled:\n",
    "            print(f\"  ✗ No transitions\")\n",
    "            expanded_nodes.add(node_id)\n",
    "            continue\n",
    "        \n",
    "        print(f\"  → {len(enabled)} transitions enabled\")\n",
    "        \n",
    "        # STRATEGIA: Prova TUTTE le transizioni abilitate\n",
    "        # Se il server crea rami diversi, li raccogliamo tutti\n",
    "        all_children_map = {}  # child_id -> child_node\n",
    "        \n",
    "        # Prova con default prima\n",
    "        try:\n",
    "            print(f\"    • Trying default expansion\")\n",
    "            response = client.expand_node(shared_state, node_id, choices=[])\n",
    "            \n",
    "            for key in (\"bpmn\", \"petri_net\", \"petri_net_dot\", \"execution_tree\"):\n",
    "                if key in response:\n",
    "                    shared_state[key] = response[key]\n",
    "            \n",
    "            updated_node = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "            if updated_node and updated_node.get(\"children\"):\n",
    "                for child in updated_node[\"children\"]:\n",
    "                    all_children_map[child[\"id\"]] = child\n",
    "                    print(f\"      ✓ Child: {child['id']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      ✗ Error: {e}\")\n",
    "        \n",
    "        # Se abbiamo raccolto 1 solo figlio e ci sono MOLTE transizioni,\n",
    "        # prova a espandere con alcune specifiche per vedere se crea rami diversi\n",
    "        if len(all_children_map) == 1 and len(enabled) > 1:\n",
    "            print(f\"    • Only 1 child so far, trying specific transitions...\")\n",
    "            # Prova fino a 5 transizioni diverse\n",
    "            for trans_name in enabled[:5]:\n",
    "                try:\n",
    "                    print(f\"      • Trying {trans_name}\")\n",
    "                    response = client.expand_node(shared_state, node_id, choices=[trans_name])\n",
    "                    \n",
    "                    for key in (\"bpmn\", \"petri_net\", \"petri_net_dot\", \"execution_tree\"):\n",
    "                        if key in response:\n",
    "                            shared_state[key] = response[key]\n",
    "                    \n",
    "                    updated_node = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "                    if updated_node and updated_node.get(\"children\"):\n",
    "                        for child in updated_node[\"children\"]:\n",
    "                            if child[\"id\"] not in all_children_map:\n",
    "                                all_children_map[child[\"id\"]] = child\n",
    "                                print(f\"        ✓ NEW child: {child['id']}\")\n",
    "                            else:\n",
    "                                print(f\"        = Same child: {child['id']}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"        ✗ Error: {e}\")\n",
    "        \n",
    "        # Aggiorna il nodo con TUTTI i children raccolti\n",
    "        if len(all_children_map) > 1:\n",
    "            print(f\"    → Merging {len(all_children_map)} children\")\n",
    "            node_to_update = get_node_by_id(shared_state[\"execution_tree\"][\"root\"], node_id)\n",
    "            if node_to_update:\n",
    "                node_to_update[\"children\"] = list(all_children_map.values())\n",
    "        \n",
    "        # Metti tutti i figli in coda\n",
    "        for child in all_children_map.values():\n",
    "            frontier.append(child[\"id\"])\n",
    "        \n",
    "        expanded_nodes.add(node_id)\n",
    "    \n",
    "    print(f\"\\n✓ Complete: {iteration} iterations, {len(expanded_nodes)} nodes\")\n",
    "    print(f\"  Total tree nodes: {count_nodes(shared_state['execution_tree']['root'])}\")\n",
    "    \n",
    "    return shared_state\n",
    ""
   ],
   "id": "96105937b6b21b2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esecuzione della costruzione parallela\n",
    "\n",
    "L'esempio seguente utilizza quattro thread. Alla fine viene mostrato il numero totale di nodi generati.\n"
   ],
   "id": "a12fe907eac064a8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "parse_tree_payload = parse_tree\n",
    "# Copia con tipi normalizzati per eventuali utility locali\n",
    "parse_tree_dict = normalize_parse_tree(parse_tree_payload)\n",
    "impacts_names = bpmn_definition.get(IMPACTS_NAMES, [])\n",
    "\n"
   ],
   "id": "b933e8242ca2bb1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "client = SimulatorClient()\n",
    "builder = ParallelExecutionTreeBuilder(client, max_workers=4)\n",
    "\n",
    "shared_state_parallel = builder.build(parse_tree_payload)\n",
    "parallel_root = shared_state_parallel[\"execution_tree\"][\"root\"]\n",
    "print(\"Numero totale di nodi generati (parallelo):\", count_nodes(parallel_root))\n",
    "\n",
    "shared_state_complete = build_complete_execution_tree(client, parse_tree_payload)\n",
    "complete_root = shared_state_complete[\"execution_tree\"][\"root\"]\n",
    "print(\"Numero totale di nodi generati (algoritmo completo):\", count_nodes(complete_root))\n",
    "\n",
    "execution_tree = shared_state_complete[\"execution_tree\"]\n",
    "current_node_id = execution_tree.get(\"current_node\")\n",
    "converted_root = clone_with_children(execution_tree.get(\"root\", {}))\n",
    "highlight_path = get_path_to_current_node(converted_root, current_node_id) or []\n",
    "dot_source = wrapper_execution_tree_to_dot(converted_root, impacts_names, highlight_path)\n",
    "graph = graphviz.Source(dot_source, format=\"svg\")\n",
    "display(graph)\n"
   ],
   "id": "53a95b5bdc2e66ac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
